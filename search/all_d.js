var searchData=
[
  ['language_20model_20vlm_20chatbot_20with_20tinychatengine_0',['Deploy vision language model (VLM) chatbot with TinyChatEngine',['../index.html#autotoc_md14',1,'']]],
  ['laptop_3a_1',['Code LLaMA Demo on an NVIDIA GeForce RTX 4070 laptop:',['../index.html#autotoc_md1',1,'']]],
  ['layernorm_2',['LayerNorm',['../classLayerNorm.html',1,'']]],
  ['layernorm_5fparams_3',['LayerNorm_params',['../structLayerNorm__params.html',1,'']]],
  ['layernormq_4',['LayerNormQ',['../classLayerNormQ.html',1,'']]],
  ['layernormq_5fparams_5',['LayerNormQ_params',['../structLayerNormQ__params.html',1,'']]],
  ['library_6',['TinyChatEngine: On-Device LLM Inference Library',['../index.html#autotoc_md0',1,'']]],
  ['linear_5ffp_7',['Linear_FP',['../classLinear__FP.html',1,'']]],
  ['linear_5ffp_5fint4_8',['Linear_FP_int4',['../classLinear__FP__int4.html',1,'']]],
  ['llama_20chat_20demo_20on_20an_20apple_20macbook_20pro_20m1_202021_20_3a_9',['LLaMA Chat Demo on an Apple MacBook Pro (M1, 2021):',['../index.html#autotoc_md3',1,'']]],
  ['llama_20demo_20on_20an_20nvidia_20geforce_20rtx_204070_20laptop_3a_10',['Code LLaMA Demo on an NVIDIA GeForce RTX 4070 laptop:',['../index.html#autotoc_md1',1,'']]],
  ['llama2_207b_20chat_20with_20tinychatengine_11',['Step-by-step to Deploy LLaMA2-7B-chat with TinyChatEngine',['../index.html#autotoc_md12',1,'']]],
  ['llama_5ffile_12',['llama_file',['../structllama__file.html',1,'']]],
  ['llama_5fsp_5fbigram_13',['llama_sp_bigram',['../structllama__sp__bigram.html',1,'']]],
  ['llama_5fsp_5fsymbol_14',['llama_sp_symbol',['../structllama__sp__symbol.html',1,'']]],
  ['llama_5ftokenizer_15',['llama_tokenizer',['../structllama__tokenizer.html',1,'']]],
  ['llama_5fvocab_16',['llama_vocab',['../structllama__vocab.html',1,'']]],
  ['llamarmsnorm_17',['LlamaRMSNorm',['../classLlamaRMSNorm.html',1,'']]],
  ['llava_5fimage_5fembed_18',['llava_image_embed',['../structllava__image__embed.html',1,'']]],
  ['llm_20compression_3a_20smoothquant_20and_20awq_19',['LLM Compression: SmoothQuant and AWQ',['../index.html#autotoc_md5',1,'']]],
  ['llm_20inference_20engine_3a_20tinychatengine_20',['LLM Inference Engine: TinyChatEngine',['../index.html#autotoc_md6',1,'']]],
  ['llm_20inference_20library_21',['TinyChatEngine: On-Device LLM Inference Library',['../index.html#autotoc_md0',1,'']]]
];
